import requests
import re
import json
import zlib
import base64
import xml.etree.ElementTree as ET
from urllib.parse import urlparse

# =========================
# 설정
# =========================
BASE_URL = "https://your-confluence.example.com/confluence"  # 뒤에 /confluence 없는 환경이면 제거
AUTH = ("your_username_or_email", "your_api_token_or_password")
HEADERS = {"Accept": "application/json"}

# 일괄 치환 룰: 왼쪽을 오른쪽으로 모두 바꿉니다.
REWRITE_MAP = {
    "https://devops-qa.martindev.co.kr/confluence/x/fAAyQw": "https://devops-qa.martindev.co.kr/confluence/x/fgAyQw",
    # 예) 도메인 이전:
    # "https://old.example.com": "https://new.example.com",
}

# 처리할 페이지 ID들
PAGE_IDS = [
    # "123456",
]

# =========================
# 유틸: 본문 정제/치환
# =========================
def sanitize_storage_format(html: str) -> str:
    # Confluence PUT 파서가 싫어하는 요소 최소 정제
    html = html.replace('\xa0', ' ')  # NBSP → space
    # table 내부의 h1 같은 블록 요소는 위험. 시각 유지용 p 변환(필요 시 주석 해제)
    html = re.sub(r'(<td[^>]*>)\s*<h1([^>]*)>(.*?)</h1>\s*(</td>)',
                  r'\1<p\2 style="font-size:1.6em; font-weight:bold;">\3</p>\4', html, flags=re.DOTALL)
    # draw.io 이미지 잔재(없어도 무방)
    # html = re.sub(r'<ac:image[\s\S]*?</ac:image>', '', html)
    return html

def rewrite_urls_in_storage(html: str, mapping: dict) -> str:
    # 단순 문자열 치환 + href/src 속성 타깃 정밀 치환
    out = html
    # 1) 안전한 정밀 치환: href/src 속성 값에 대해 매핑 적용
    def repl_attr(m):
        before = m.group(2)
        after = mapping.get(before, before)
        return f'{m.group(1)}"{after}"'

    # href="...":, src="...":
    out = re.sub(r'(href|src)\s*=\s*"([^"]+)"', repl_attr, out)

    # 2) 원문 그대로 등장하는 URL도 치환 (표 안 텍스트 등)
    for old, new in mapping.items():
        out = out.replace(old, new)
    return out

# =========================
# 유틸: draw.io(.drawio/.drawio.svg) 다루기
# =========================
def list_attachments(page_id: str):
    # 모든 첨부 조회(페이지 크면 페이징 필요) — 간단히 size=500 가정
    url = f"{BASE_URL}/rest/api/content/{page_id}/child/attachment?limit=500"
    r = requests.get(url, headers=HEADERS, auth=AUTH)
    r.raise_for_status()
    return r.json().get("results", [])

def download_attachment(attachment_id: str):
    # 다운로드 링크 얻기
    url = f"{BASE_URL}/rest/api/content/{attachment_id}/download"
    r = requests.get(url, headers=HEADERS, auth=AUTH, allow_redirects=True)
    r.raise_for_status()
    return r.content, r.headers.get("Content-Type", "")

def upload_new_attachment_version(page_id: str, attachment_id: str, filename: str, data: bytes, content_type: str):
    # 새 버전 업로드 (multipart)
    url = f"{BASE_URL}/rest/api/content/{page_id}/child/attachment/{attachment_id}/data"
    files = {
        'file': (filename, data, content_type or 'application/octet-stream')
    }
    r = requests.post(url, headers={}, auth=AUTH, files=files)
    r.raise_for_status()
    return r.json()

# ----- draw.io 디코딩/인코딩 -----
def try_decompress_drawio_text(s: str) -> str:
    """
    <diagram> 텍스트가 종종 base64 + deflate 로 압축되어 있습니다.
    압축된 경우 풀어서 XML(Text)로, 아니면 원문 반환.
    """
    try:
        raw = base64.b64decode(s)
        # -15: raw DEFLATE (zlib 헤더 없음)
        xml = zlib.decompress(raw, -15).decode('utf-8', errors='replace')
        return xml
    except Exception:
        return s  # 압축 안된 평문일 가능성

def compress_drawio_text(s: str) -> str:
    """
    편집한 평문 XML을 다시 deflate + base64로 압축.
    """
    comp = zlib.compress(s.encode('utf-8'))  # zlib 헤더 포함
    # draw.io는 raw deflate(-15) + base64를 주로 사용. zlib 헤더 제거 필요.
    # zlib 포맷: 2바이트 헤더 + ... + 4바이트 Adler-32
    # 간단하게 raw deflate로 재압축:
    comp_raw = zlib.compressobj(level=9, wbits=-15)
    data = comp_raw.compress(s.encode('utf-8')) + comp_raw.flush()
    return base64.b64encode(data).decode('ascii')

def rewrite_urls_in_drawio_xml(xml_text: str, mapping: dict) -> str:
    """
    draw.io 평문 XML(mxl, mxfile 내부) 내 URL 문자열 치환.
    링크는 보통 mxCell/@link 또는 userObject/@link, 또는 style 내 'link=' 형태로 존재.
    """
    # 1) 속성 치환: link, url, href 등
    def repl_attr_value(match):
        before = match.group(2)
        after = mapping.get(before, before)
        return f'{match.group(1)}="{after}"'

    out = re.sub(r'(link|url|href)\s*=\s*"([^"]+)"', repl_attr_value, xml_text)

    # 2) 스타일 문자열 내 link=...
    def repl_style_link(m):
        style = m.group(0)
        for old, new in mapping.items():
            style = style.replace(f"link={old}", f"link={new}")
        return style
    out = re.sub(r'style="[^"]+"', repl_style_link, out)

    # 3) 텍스트 노드에 순수 URL이 있을 수도 있음
    for old, new in mapping.items():
        out = out.replace(old, new)

    return out

def process_drawio_attachment(page_id: str, att: dict, mapping: dict):
    filename = att.get("title") or att.get("metadata", {}).get("filename")
    if not filename:
        return False, "no-filename"

    name = filename.lower()
    if not (name.endswith(".drawio") or name.endswith(".drawio.svg")):
        return False, "skip-non-drawio"

    attachment_id = att["id"]
    data, ctype = download_attachment(attachment_id)

    text = None
    if name.endswith(".drawio"):
        # XML 텍스트
        text = data.decode('utf-8', errors='replace')
        # <mxfile><diagram>...</diagram></mxfile> 형태. diagram 텍스트가 압축일 수 있음
        try:
            root = ET.fromstring(text)
        except Exception as e:
            return False, f"xml-parse-failed: {e}"

        changed = False
        for diag in root.findall(".//diagram"):
            payload = diag.text or ""
            plain = try_decompress_drawio_text(payload)
            new_plain = rewrite_urls_in_drawio_xml(plain, mapping)
            if new_plain != plain:
                changed = True
                # 재압축 결정: 원본이 압축이었다면 압축으로, 아니면 평문으로
                if payload.strip() and payload.strip() != plain.strip():
                    # 원본이 압축이었던 것으로 간주 → 재압축
                    diag.text = compress_drawio_text(new_plain)
                else:
                    diag.text = new_plain

        if not changed:
            return False, "no-change"

        new_bytes = ET.tostring(root, encoding="utf-8", method="xml")
        upload_new_attachment_version(page_id, attachment_id, filename, new_bytes, "application/xml")
        return True, "updated"

    elif name.endswith(".drawio.svg"):
        # SVG는 XML이므로 텍스트 치환 시도
        text = data.decode('utf-8', errors='replace')
        new_text = rewrite_urls_in_drawio_xml(text, mapping)
        if new_text == text:
            return False, "no-change"
        new_bytes = new_text.encode('utf-8')
        upload_new_attachment_version(page_id, attachment_id, filename, new_bytes, "image/svg+xml")
        return True, "updated"

    return False, "unknown-case"

# =========================
# 페이지 본문 GET/PUT
# =========================
def get_page(pid: str):
    url = f"{BASE_URL}/rest/api/content/{pid}?expand=body.storage,version"
    r = requests.get(url, headers=HEADERS, auth=AUTH)
    r.raise_for_status()
    return r.json()

def put_page(pid: str, title: str, version: int, storage_value: str):
    payload = {
        "id": pid,
        "type": "page",
        "title": title,
        "version": {"number": version + 1},
        "body": {"storage": {"value": storage_value, "representation": "storage"}}
    }
    url = f"{BASE_URL}/rest/api/content/{pid}"
    r = requests.put(url, headers={"Content-Type": "application/json"}, auth=AUTH, data=json.dumps(payload, ensure_ascii=False))
    if r.status_code != 200:
        raise Exception(f"PUT failed {r.status_code}: {r.text[:500]}")
    return r.json()

# =========================
# 메인 로직
# =========================
def process_page(pid: str, mapping: dict):
    print(f"\n=== Page {pid} ===")
    page = get_page(pid)
    title = page["title"]
    version = page["version"]["number"]
    storage = page["body"]["storage"]["value"]

    # 1) draw.io 첨부 처리 (선수처리 권장: 본문 링크만 바꿔도 되지만, 첨부 내부 링크가 더 중요할 때가 많음)
    atts = list_attachments(pid)
    updated_any_diagram = False
    for att in atts:
        ok, msg = process_drawio_attachment(pid, att, mapping)
        print(f" - attachment {att.get('title') or att.get('id')} -> {msg}")
        if ok:
            updated_any_diagram = True

    # 2) 본문 링크 치환 + 정제 후 PUT
    new_storage = rewrite_urls_in_storage(storage, mapping)
    new_storage = sanitize_storage_format(new_storage)

    if new_storage != storage:
        try:
            put_page(pid, title, version, new_storage)
            print(" - page body: updated")
        except Exception as e:
            print(f" - page body: PUT failed: {e}")
    else:
        print(" - page body: no-change")

    return True

if __name__ == "__main__":
    for pid in PAGE_IDS:
        try:
            process_page(pid, REWRITE_MAP)
        except Exception as e:
            print(f"[ERROR] page {pid}: {e}")
