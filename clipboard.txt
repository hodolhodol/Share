# 일반 링크 변경 + 짧은 URL 수집

import requests, re, csv, time, certifi, urllib.parse, json
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from drawio_utils import replace_links_drawio
import os
# 설정
#설정 - 검증서버
load_dotenv()

EMAIL = os.getenv("EMAIL")
API_TOKEN = os.getenv("API_TOKEN")


BASE_URL = "https://devops-qa.martin.co.kr/confluence"   # 또는 내부 도메인
PAGE_ID = "823654206"  # 테스트할 Confluence 페이지 ID
CERT_PATH = "..."
ROOT_PAGE_ID = "1066435477"  # 테스트할 Confluence 페이지 ID

# ORIGIN_SPACES = ['TR', 'AGILEK', 'DCO']
# TARGET_SPACE = 'Knowledge'
ORIGIN_SPACES = ['TR', 'AGILEK', 'DCO']
TARGET_SPACE = 'ARU'

TESTPAGE = 'TESTPAGE'

auth = (EMAIL, API_TOKEN)
headers = {
    "Authorization": f"Bearer {API_TOKEN}",  # Bearer 토큰 방식으로 인증
   "Content-Type": "application/json",
#    "Accept": "application/json"
}

short_urls = {}
pageid_urls = {}



def get_all_page_ids(space_key):
    ids = []
    start = 0
    while True:
        url = f"{BASE_URL}/rest/api/content?spaceKey={space_key}&limit=50&start={start}&expand=version"
        res = requests.get(url, headers=headers)
        results = res.json().get("results", [])
        if not results: break
        for page in results:
            ids.append((page['id'], page['title']))
        start += 50
    return ids
def get_child_pages(parent_id):
    """지정한 페이지 ID 이하의 모든 하위 페이지 ID+제목 리스트 반환"""
    pages = []
    stack = [parent_id]

    while stack:
        current_id = stack.pop()
        url = f"{BASE_URL}/rest/api/content/{current_id}?expand=children.page"
        #res = requests.get(url, auth=auth)
        res = requests.get(url, headers=headers)
        if res.status_code != 200:
            print(f"❌ Failed to get children of {current_id}")
            continue

        data = res.json()
        title = data.get("title", "Untitled")
        pages.append((current_id, title))

        children = data.get("children", {}).get("page", {}).get("results", [])
        for child in children:
            stack.append(child["id"])
    return pages
  
def replace_links_spacekey(body):
    for space in ORIGIN_SPACES:
        #body = re.sub(rf'{BASE_URL}/display/{space}/', f'{BASE_URL}/display/{TARGET_SPACE}/', body)
        body = re.sub(rf'{BASE_URL}/display/{space}/', f'{BASE_URL}/display/{TARGET_SPACE}/', body)         
        body = re.sub(rf'/display/{space}/', f'{BASE_URL}/display/{TARGET_SPACE}/', body)   
        

        body = re.sub(rf'/spaces/{space}/pages/', f'/spaces/{TARGET_SPACE}/pages/', body)
        body = re.sub(rf'https://[^"]+/wiki/display/{space}/', f'/display/{TARGET_SPACE}/', body)
        body = re.sub(rf'https://[^"]+/wiki/spaces/{space}/pages/', f'/spaces/{TARGET_SPACE}/pages/', body)
        body = re.sub(rf'link="[^"]*/spaces/{space}/pages/', lambda m: m.group(0).replace(f'/spaces/{space}/', f'/spaces/{TARGET_SPACE}/'), body)
    return body

def replace_links_tinyui(body, title, page_id):
    matches = re.findall(rf'{BASE_URL}/x/[a-zA-Z0-9]+', body)
    for m in matches:
        partial = "".join(m)
        short_url = f"{BASE_URL}{partial}" if partial.startswith('/x') or '/wiki/x' in partial else partial
        if short_url not in short_urls:
            new_url = get_new_short_url(short_url, TARGET_SPACE)
            short_urls[short_url] = new_url
            body = re.sub(short_url, new_url, body)
            print(f"🔗 Replaced {short_url} with {new_url}")

        # else:
        #     print(f"❌ 이 short url은 수정되었어야 함 {short_url}")
        #    continue
    
    return body

def replace_links_page_id(body):
    matches = re.findall(rf'{BASE_URL}/pages/viewpage\.action\?pageId=\d+', body)
    for m in matches:
        page_id = extract_page_id(m)
        if page_id in pageid_urls:
            continue
#        if page_id == pageid_urls[page_id] : continue #page_id 동일하면 space가 origin_space에 있던게 아니다. 즉, 변경할 필요가 없다.
        page_info = get_page_info_by_id(page_id)
        if page_info is None:
            print(f"❌ Page not found: {page_id}")
            continue
        space = page_info['_expandable']['space'].strip('/').split('/')[-1] #space path의 맨마지막 가지고 옴
        title = page_info['title']
        if space in ORIGIN_SPACES:
                target_page_info = get_page_info_by_title(TARGET_SPACE, title)
                if target_page_info:
                    target_page_id = target_page_info.get('id')
                    old_url = m
                    new_url = f"{BASE_URL}/pages/viewpage.action?pageId={target_page_id}"
                    body = body.replace(old_url, new_url)
                    print(f"🔗 Replaced {old_url} with {new_url}")
                    pageid_urls[page_id] = target_page_id
        else :
            pageid_urls[page_id] = page_id #page_id 동일하면 space가 origin_space에 있던게 아니다. 즉, 변경할 필요가 없다.

    return body


def resolve_short_url_to_title(short_url):
    """
    short URL을 풀어서 page ID 반환
    :param short_url: e.g. https://your-domain.atlassian.net/x/AbCdE
    :param auth: requests basic auth tuple (username, API token)
    """
    response = requests.get(short_url, headers=headers, allow_redirects=True)
    
    # 최종 리디렉션 URL에서 page ID 추출
    title = response.url.split('/')[-1].replace('+', ' ') # url에서는 스페이스가 +로 나와서.
    return title
    
    return title

    
def resolve_tiny_url(short_url):
    response = requests.get(short_url, allow_redirects=False, headers=headers)
    if response.status_code in [301, 302]:
        return response.headers['Location']
    else:
        raise Exception(f"리디렉션 실패: status code {response.status_code}")

# 2. URL에서 page ID 추출 (e.g. /pages/viewpage.action?pageId=12345678)
def extract_page_id(full_url):
    match = re.search(r"pageId=(\d+)", full_url)
    if match:
        return match.group(1)
    else:
        raise Exception(f"pageId를 찾을 수 없습니다: {full_url}")
    
def get_page_info_by_id(page_id):
    """
    page ID로 title 등 페이지 정보 조회
    """
    url = f"{BASE_URL}/rest/api/content/{page_id}"
    params = {"expand": "title"}
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()
    return response.json()
    


def get_short_url_by_title(title, space_key, base_url):
    """
    주어진 title로 페이지를 검색하고 short URL(tiny link)을 반환
    """
    # 1. 제목으로 페이지 조회
    url = f"{base_url}/rest/api/search"
    params = {
        "title": title,
        "space": space_key,
        "expand": "version"  # title 존재 유무 확인용
    }
    resp = requests.get(url, headers=headers, params=params)
    resp.raise_for_status()
    data = resp.json()
    
    # 2. 결과 없을 경우 처리
    if not data.get("results"):
        print("Martin", "get_short_url_by_title", "해당 페이지 없음 {title}")
        return None  # or raise Exception("Page not found")
    
    page = data["results"][0]
    page_id = page["id"]
    
    # 3. 페이지 ID로 tiny link 정보 가져오기
    url = f"{base_url}/rest/api/content/{page_id}?expand=shortUrl,tinyui"
    resp = requests.get(url, auth=auth)
    resp.raise_for_status()
    page_data = resp.json()

    # 4. shortUrl 필드가 존재할 경우 반환
    tiny_url = page_data.get("tinyui", {}).get("link")
    if tiny_url:
        return f"{base_url}{tiny_url}"
    else:
        return None
    
def url_encode_query(query_string):
    """
    Encodes the given query string for use in a URL.

    Args:
    query_string (str): The query string to encode.

    Returns:
    str: The URL-encoded query string.
    """
    return urllib.parse.quote_plus(query_string)

def get_page_info_by_title(space_key, title):
    url = f"{BASE_URL}/rest/api/search"
    params = {
        'cql': f'title="{title}" AND space="{space_key}"',
        'limit': 10
    }
    
    response = requests.get(url, headers=headers, params=params)

    if response.status_code != 200:
        raise Exception(f"Request failed with status code {response.status_code}")
    
    data = response.json()
    results = data.get('results', [])
    
    if not results:
        return None
    
    for result in results:
        if result.get('title') == title:
            return {
                "id" :  result['content']['id'],
                "title" :  result['content']['title'],
                "webui" :  result['content']['_links']['webui'],
                "tinyui" :  result['content']['_links']['tinyui']
            }
    return None


def get_new_short_url(short_url, new_space):
    # Step 1: Extract the page ID from the short URL
    title = resolve_short_url_to_title(short_url)
    new_short_url = get_page_info_by_title(TARGET_SPACE, title)['tinyui']   

    if new_short_url:
        return f"{BASE_URL}{new_short_url}"
    else:
        return None
        

def update_page(pid, title):
    url = f"{BASE_URL}/rest/api/content/{pid}?expand=body.storage,version"
    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        print(f"❌ Failed to get {title}")
        return

    data = res.json()
    body = data['body']['storage']['value']
    version = data['version']['number']
    
    new_body = replace_links_spacekey(body)
    new_body = replace_links_tinyui(new_body, title, pid)
    new_body = replace_links_page_id(new_body)
    new_body = replace_links_drawio(newbody, data)
    if new_body == body:
        print(f"🔍 No change: {title}")
        return


    space = data['_expandable']['space'].strip('/').split('/')[-1] #space path의 맨마지막 가지고 옴
    payload = {
        "id": pid,
        "type": "page",
        "title": title,
        "space": {"key": space},
        # "body": {"storage": {"value": "hello world", "representation": "storage"}},
        "body": {"storage": {"value": new_body, "representation": "storage"}},
        "version": {"number": version + 1}
    }

    put_url = f"{BASE_URL}/rest/api/content/{pid}"
    put_res = requests.put(put_url, json=payload, headers=headers)
    print(f"{'✅ Updated' if put_res.status_code == 200 else '❌ Failed'}: {title}")

def set_variables(mode) :
    global BASE_URL, PAGE_ID, ORIGIN_SPACES, TARGET_SPACE
    if mode == "TEST" :
        BASE_URL = "https://devops-qa.martin.co.kr/confluence"
        PAGE_ID = "1127350378"
        ORIGIN_SPACES = ['TPG']
        TARGET_SPACE = 'ARU'

if __name__ == "__main__":
#    test_short_url()
    set_variables("TEST")
    update_page(PAGE_ID, TESTPAGE)

    # pages = get_child_pages(ROOT_PAGE_ID)
    # print(f"🔍 Pages under root {ROOT_PAGE_ID}: {len(pages)}")

    # for pid, title in pages:
    #     update_page(pid, title)
    #     time.sleep(0.5)

    filename = 'short_urls.csv'
    with open(filename, mode='w', newline='', encoding='utf-8') as file:
        fieldnames = ['old_url', 'new_url']
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        for old_url, new_url in short_urls.items():
            writer.writerow({'old_url': old_url, 'new_url': new_url})


    print(f"\n⚠️ Short URLs written to short_urls.csv: {len(short_urls)}")
